From 1118129a74a1911ad4990bb9c66bd327587e9754 Mon Sep 17 00:00:00 2001
From: Nicolas Liochon <nkeywal@apache.org>
Date: Wed, 29 Jan 2014 20:42:44 +0000
Subject: [PATCH 25/73] HBASE-10431 Rename com.google.protobuf.ZeroCopyLiteralByteString

Reason: Compatibility
Author: Nicolas Liochon
Ref: CDH-17196

git-svn-id: https://svn.apache.org/repos/asf/hbase/branches/0.96@1562586 13f79535-47bb-0310-9956-ffa450edef68
---
 .../org/apache/hadoop/hbase/ClusterStatus.java     |    5 +-
 .../org/apache/hadoop/hbase/HColumnDescriptor.java |    8 +-
 .../java/org/apache/hadoop/hbase/HRegionInfo.java  |    6 +-
 .../org/apache/hadoop/hbase/HTableDescriptor.java  |    6 +-
 .../org/apache/hadoop/hbase/RegionTransition.java  |    6 +-
 .../coprocessor/BigDecimalColumnInterpreter.java   |    5 +-
 .../client/coprocessor/SecureBulkLoadClient.java   |    9 +-
 .../hadoop/hbase/filter/ByteArrayComparable.java   |    5 +-
 .../hbase/filter/ColumnPaginationFilter.java       |    4 +-
 .../hadoop/hbase/filter/ColumnPrefixFilter.java    |    4 +-
 .../hadoop/hbase/filter/ColumnRangeFilter.java     |    6 +-
 .../hadoop/hbase/filter/DependentColumnFilter.java |    6 +-
 .../FirstKeyValueMatchingQualifiersFilter.java     |    4 +-
 .../apache/hadoop/hbase/filter/FuzzyRowFilter.java |    6 +-
 .../hadoop/hbase/filter/InclusiveStopFilter.java   |    4 +-
 .../hbase/filter/MultipleColumnPrefixFilter.java   |    4 +-
 .../apache/hadoop/hbase/filter/PrefixFilter.java   |    4 +-
 .../hbase/filter/SingleColumnValueFilter.java      |    6 +-
 .../hbase/ipc/MasterCoprocessorRpcChannel.java     |    4 +-
 .../hbase/ipc/RegionCoprocessorRpcChannel.java     |    4 +-
 .../apache/hadoop/hbase/protobuf/ProtobufUtil.java |   80 ++++++++++----------
 .../hadoop/hbase/protobuf/RequestConverter.java    |   44 ++++++------
 .../org/apache/hadoop/hbase/zookeeper/ZKUtil.java  |    4 +-
 .../hadoop/hbase/client/TestClientNoCluster.java   |   16 ++--
 .../google/protobuf/HBaseZeroCopyByteString.java   |   63 +++++++++++++++
 .../google/protobuf/ZeroCopyLiteralByteString.java |   63 ---------------
 .../java/org/apache/hadoop/hbase/io/Reference.java |    6 +-
 .../org/apache/hadoop/hbase/io/hfile/HFile.java    |    6 +-
 .../hbase/protobuf/ReplicationProtbufUtil.java     |    8 +-
 .../hadoop/hbase/regionserver/HRegionServer.java   |    6 +-
 .../hadoop/hbase/regionserver/wal/HLogKey.java     |    8 +-
 .../apache/hadoop/hbase/rest/model/CellModel.java  |    7 +-
 .../hadoop/hbase/rest/model/CellSetModel.java      |    9 +-
 .../hadoop/hbase/rest/model/ScannerModel.java      |    8 +-
 .../rest/model/StorageClusterStatusModel.java      |    5 +-
 .../hadoop/hbase/rest/model/TableInfoModel.java    |    7 +-
 .../hbase/coprocessor/TestCoprocessorEndpoint.java |    6 +-
 .../coprocessor/TestRowProcessorEndpoint.java      |   14 ++--
 .../hadoop/hbase/protobuf/TestProtobufUtil.java    |   10 +-
 .../hadoop/hbase/regionserver/TestPriorityRpc.java |   25 +++---
 .../regionserver/TestReplicationSink.java          |    7 +-
 41 files changed, 249 insertions(+), 259 deletions(-)
 create mode 100644 hbase-protocol/src/main/java/com/google/protobuf/HBaseZeroCopyByteString.java
 delete mode 100644 hbase-protocol/src/main/java/com/google/protobuf/ZeroCopyLiteralByteString.java

diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterStatus.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterStatus.java
index 1fa4a9b..53704ea 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterStatus.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/ClusterStatus.java
@@ -26,6 +26,7 @@ import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.hbase.master.RegionState;
@@ -40,8 +41,6 @@ import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Re
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.io.VersionedWritable;
 
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 
 /**
  * Status information on the HBase cluster.
@@ -335,7 +334,7 @@ public class ClusterStatus extends VersionedWritable {
         ClusterStatusProtos.RegionState rs = rit.getValue().convert();
         RegionSpecifier.Builder spec =
             RegionSpecifier.newBuilder().setType(RegionSpecifierType.REGION_NAME);
-        spec.setValue(ZeroCopyLiteralByteString.wrap(Bytes.toBytes(rit.getKey())));
+        spec.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(rit.getKey())));
 
         RegionInTransition pbRIT =
             RegionInTransition.newBuilder().setSpec(spec.build()).setRegionState(rs).build();
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java
index 548aed6..72b2a83 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/HColumnDescriptor.java
@@ -19,8 +19,8 @@
 package org.apache.hadoop.hbase;
 
 import com.google.common.base.Preconditions;
+import com.google.protobuf.HBaseZeroCopyByteString;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
@@ -1180,11 +1180,11 @@ public class HColumnDescriptor implements WritableComparable<HColumnDescriptor>
    */
   public ColumnFamilySchema convert() {
     ColumnFamilySchema.Builder builder = ColumnFamilySchema.newBuilder();
-    builder.setName(ZeroCopyLiteralByteString.wrap(getName()));
+    builder.setName(HBaseZeroCopyByteString.wrap(getName()));
     for (Map.Entry<ImmutableBytesWritable, ImmutableBytesWritable> e: this.values.entrySet()) {
       BytesBytesPair.Builder aBuilder = BytesBytesPair.newBuilder();
-      aBuilder.setFirst(ZeroCopyLiteralByteString.wrap(e.getKey().get()));
-      aBuilder.setSecond(ZeroCopyLiteralByteString.wrap(e.getValue().get()));
+      aBuilder.setFirst(HBaseZeroCopyByteString.wrap(e.getKey().get()));
+      aBuilder.setSecond(HBaseZeroCopyByteString.wrap(e.getValue().get()));
       builder.addAttributes(aBuilder.build());
     }
     for (Map.Entry<String, String> e : this.configuration.entrySet()) {
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java
index 6525bef..a5907d6 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/HRegionInfo.java
@@ -29,6 +29,7 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -47,7 +48,6 @@ import org.apache.hadoop.hbase.util.PairOfSameType;
 import org.apache.hadoop.io.DataInputBuffer;
 
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * HRegion information.
@@ -842,10 +842,10 @@ public class HRegionInfo implements Comparable<HRegionInfo> {
     builder.setTableName(ProtobufUtil.toProtoTableName(info.getTable()));
     builder.setRegionId(info.getRegionId());
     if (info.getStartKey() != null) {
-      builder.setStartKey(ZeroCopyLiteralByteString.wrap(info.getStartKey()));
+      builder.setStartKey(HBaseZeroCopyByteString.wrap(info.getStartKey()));
     }
     if (info.getEndKey() != null) {
-      builder.setEndKey(ZeroCopyLiteralByteString.wrap(info.getEndKey()));
+      builder.setEndKey(HBaseZeroCopyByteString.wrap(info.getEndKey()));
     }
     builder.setOffline(info.isOffline());
     builder.setSplit(info.isSplit());
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
index 574542b..647d351 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/HTableDescriptor.java
@@ -34,6 +34,7 @@ import java.util.TreeMap;
 import java.util.TreeSet;
 import java.util.regex.Matcher;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -54,7 +55,6 @@ import org.apache.hadoop.hbase.util.Writables;
 import org.apache.hadoop.io.WritableComparable;
 
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * HTableDescriptor contains the details about an HBase table  such as the descriptors of
@@ -1435,8 +1435,8 @@ public class HTableDescriptor implements WritableComparable<HTableDescriptor> {
     builder.setTableName(ProtobufUtil.toProtoTableName(getTableName()));
     for (Map.Entry<ImmutableBytesWritable, ImmutableBytesWritable> e: this.values.entrySet()) {
       BytesBytesPair.Builder aBuilder = BytesBytesPair.newBuilder();
-      aBuilder.setFirst(ZeroCopyLiteralByteString.wrap(e.getKey().get()));
-      aBuilder.setSecond(ZeroCopyLiteralByteString.wrap(e.getValue().get()));
+      aBuilder.setFirst(HBaseZeroCopyByteString.wrap(e.getKey().get()));
+      aBuilder.setSecond(HBaseZeroCopyByteString.wrap(e.getValue().get()));
       builder.addAttributes(aBuilder.build());
     }
     for (HColumnDescriptor hcd: getColumnFamilies()) {
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/RegionTransition.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/RegionTransition.java
index 64f92d1..0632825 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/RegionTransition.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/RegionTransition.java
@@ -17,8 +17,8 @@
  */
 package org.apache.hadoop.hbase;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.exceptions.DeserializationException;
@@ -104,10 +104,10 @@ public class RegionTransition {
       org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder().
         setHostName(sn.getHostname()).setPort(sn.getPort()).setStartCode(sn.getStartcode()).build();
     ZooKeeperProtos.RegionTransition.Builder builder = ZooKeeperProtos.RegionTransition.newBuilder().
-      setEventTypeCode(type.getCode()).setRegionName(ZeroCopyLiteralByteString.wrap(regionName)).
+      setEventTypeCode(type.getCode()).setRegionName(HBaseZeroCopyByteString.wrap(regionName)).
         setServerName(pbsn);
     builder.setCreateTime(System.currentTimeMillis());
-    if (payload != null) builder.setPayload(ZeroCopyLiteralByteString.wrap(payload));
+    if (payload != null) builder.setPayload(HBaseZeroCopyByteString.wrap(payload));
     return new RegionTransition(builder.build());
   }
 
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/BigDecimalColumnInterpreter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/BigDecimalColumnInterpreter.java
index 408a365..cc1fcfd 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/BigDecimalColumnInterpreter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/BigDecimalColumnInterpreter.java
@@ -22,6 +22,7 @@ import java.io.IOException;
 import java.math.BigDecimal;
 import java.math.RoundingMode;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.Cell;
 import org.apache.hadoop.hbase.CellUtil;
@@ -30,8 +31,6 @@ import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg;
 import org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg;
 import org.apache.hadoop.hbase.util.Bytes;
 
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 /**
  * ColumnInterpreter for doing Aggregation's with BigDecimal columns. This class
  * is required at the RegionServer also.
@@ -122,7 +121,7 @@ public class BigDecimalColumnInterpreter extends ColumnInterpreter<BigDecimal, B
 
   private BigDecimalMsg getProtoForType(BigDecimal t) {
     BigDecimalMsg.Builder builder = BigDecimalMsg.newBuilder();
-    return builder.setBigdecimalMsg(ZeroCopyLiteralByteString.wrap(Bytes.toBytes(t))).build();
+    return builder.setBigdecimalMsg(HBaseZeroCopyByteString.wrap(Bytes.toBytes(t))).build();
   }
   
   @Override
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java
index 08cd26e..dc94895 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/coprocessor/SecureBulkLoadClient.java
@@ -21,8 +21,7 @@ package org.apache.hadoop.hbase.client.coprocessor;
 import static org.apache.hadoop.hbase.HConstants.EMPTY_START_ROW;
 import static org.apache.hadoop.hbase.HConstants.LAST_ROW;
 
-import com.google.protobuf.ByteString;
-import com.google.protobuf.ZeroCopyLiteralByteString;
+import com.google.protobuf.HBaseZeroCopyByteString;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.fs.Path;
@@ -137,8 +136,8 @@ public class SecureBulkLoadClient {
       if(userToken != null) {
         protoDT =
             SecureBulkLoadProtos.DelegationToken.newBuilder()
-              .setIdentifier(ZeroCopyLiteralByteString.wrap(userToken.getIdentifier()))
-              .setPassword(ZeroCopyLiteralByteString.wrap(userToken.getPassword()))
+              .setIdentifier(HBaseZeroCopyByteString.wrap(userToken.getIdentifier()))
+              .setPassword(HBaseZeroCopyByteString.wrap(userToken.getPassword()))
               .setKind(userToken.getKind().toString())
               .setService(userToken.getService().toString()).build();
       }
@@ -147,7 +146,7 @@ public class SecureBulkLoadClient {
           new ArrayList<ClientProtos.BulkLoadHFileRequest.FamilyPath>();
       for(Pair<byte[], String> el: familyPaths) {
         protoFamilyPaths.add(ClientProtos.BulkLoadHFileRequest.FamilyPath.newBuilder()
-          .setFamily(ZeroCopyLiteralByteString.wrap(el.getFirst()))
+          .setFamily(HBaseZeroCopyByteString.wrap(el.getFirst()))
           .setPath(el.getSecond()).build());
       }
 
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java
index 464804b..73d735a 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ByteArrayComparable.java
@@ -18,14 +18,13 @@
  */
 package org.apache.hadoop.hbase.filter;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.hbase.exceptions.DeserializationException;
 import org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos;
 import org.apache.hadoop.hbase.util.Bytes;
 
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 
 /** Base class for byte array comparators */
 @InterfaceAudience.Public
@@ -54,7 +53,7 @@ public abstract class ByteArrayComparable implements Comparable<byte[]> {
   ComparatorProtos.ByteArrayComparable convert() {
     ComparatorProtos.ByteArrayComparable.Builder builder =
       ComparatorProtos.ByteArrayComparable.newBuilder();
-    if (value != null) builder.setValue(ZeroCopyLiteralByteString.wrap(value));
+    if (value != null) builder.setValue(HBaseZeroCopyByteString.wrap(value));
     return builder.build();
   }
 
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java
index 13c7259..8094395 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java
@@ -20,6 +20,7 @@ package org.apache.hadoop.hbase.filter;
 
 import java.util.ArrayList;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.hbase.Cell;
@@ -30,7 +31,6 @@ import org.apache.hadoop.hbase.util.Bytes;
 
 import com.google.common.base.Preconditions;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * A filter, based on the ColumnCountGetFilter, takes two arguments: limit and offset.
@@ -175,7 +175,7 @@ public class ColumnPaginationFilter extends FilterBase
       builder.setOffset(this.offset);
     }
     if (this.columnOffset != null) {
-      builder.setColumnOffset(ZeroCopyLiteralByteString.wrap(this.columnOffset));
+      builder.setColumnOffset(HBaseZeroCopyByteString.wrap(this.columnOffset));
     }
     return builder.build().toByteArray();
   }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPrefixFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPrefixFilter.java
index ca346b1..a6873d9 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPrefixFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPrefixFilter.java
@@ -21,6 +21,7 @@ package org.apache.hadoop.hbase.filter;
 
 import java.util.ArrayList;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.hbase.Cell;
@@ -31,7 +32,6 @@ import org.apache.hadoop.hbase.util.Bytes;
 
 import com.google.common.base.Preconditions;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * This filter is used for selecting only those keys with columns that matches
@@ -95,7 +95,7 @@ public class ColumnPrefixFilter extends FilterBase {
   public byte [] toByteArray() {
     FilterProtos.ColumnPrefixFilter.Builder builder =
       FilterProtos.ColumnPrefixFilter.newBuilder();
-    if (this.prefix != null) builder.setPrefix(ZeroCopyLiteralByteString.wrap(this.prefix));
+    if (this.prefix != null) builder.setPrefix(HBaseZeroCopyByteString.wrap(this.prefix));
     return builder.build().toByteArray();
   }
 
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnRangeFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnRangeFilter.java
index 6bb297c..85c96f0 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnRangeFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnRangeFilter.java
@@ -22,8 +22,8 @@ package org.apache.hadoop.hbase.filter;
 import static org.apache.hadoop.hbase.util.Bytes.len;
 
 import com.google.common.base.Preconditions;
+import com.google.protobuf.HBaseZeroCopyByteString;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
@@ -173,9 +173,9 @@ public class ColumnRangeFilter extends FilterBase {
   public byte [] toByteArray() {
     FilterProtos.ColumnRangeFilter.Builder builder =
       FilterProtos.ColumnRangeFilter.newBuilder();
-    if (this.minColumn != null) builder.setMinColumn(ZeroCopyLiteralByteString.wrap(this.minColumn));
+    if (this.minColumn != null) builder.setMinColumn(HBaseZeroCopyByteString.wrap(this.minColumn));
     builder.setMinColumnInclusive(this.minColumnInclusive);
-    if (this.maxColumn != null) builder.setMaxColumn(ZeroCopyLiteralByteString.wrap(this.maxColumn));
+    if (this.maxColumn != null) builder.setMaxColumn(HBaseZeroCopyByteString.wrap(this.maxColumn));
     builder.setMaxColumnInclusive(this.maxColumnInclusive);
     return builder.build().toByteArray();
   }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/DependentColumnFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/DependentColumnFilter.java
index 236e492..32a3dcd 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/DependentColumnFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/DependentColumnFilter.java
@@ -25,6 +25,7 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.hbase.Cell;
@@ -37,7 +38,6 @@ import org.apache.hadoop.hbase.util.Bytes;
 
 import com.google.common.base.Preconditions;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * A filter for adding inter-column timestamp matching
@@ -225,10 +225,10 @@ public class DependentColumnFilter extends CompareFilter {
       FilterProtos.DependentColumnFilter.newBuilder();
     builder.setCompareFilter(super.convert());
     if (this.columnFamily != null) {
-      builder.setColumnFamily(ZeroCopyLiteralByteString.wrap(this.columnFamily));
+      builder.setColumnFamily(HBaseZeroCopyByteString.wrap(this.columnFamily));
     }
     if (this.columnQualifier != null) {
-      builder.setColumnQualifier(ZeroCopyLiteralByteString.wrap(this.columnQualifier));
+      builder.setColumnQualifier(HBaseZeroCopyByteString.wrap(this.columnQualifier));
     }
     builder.setDropDependentColumn(this.dropDependentColumn);
     return builder.build().toByteArray();
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FirstKeyValueMatchingQualifiersFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FirstKeyValueMatchingQualifiersFilter.java
index ccb356e..edee29a 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FirstKeyValueMatchingQualifiersFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FirstKeyValueMatchingQualifiersFilter.java
@@ -19,8 +19,8 @@
 package org.apache.hadoop.hbase.filter;
 
 import com.google.protobuf.ByteString;
+import com.google.protobuf.HBaseZeroCopyByteString;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
@@ -89,7 +89,7 @@ public class FirstKeyValueMatchingQualifiersFilter extends FirstKeyOnlyFilter {
     FilterProtos.FirstKeyValueMatchingQualifiersFilter.Builder builder =
       FilterProtos.FirstKeyValueMatchingQualifiersFilter.newBuilder();
     for (byte[] qualifier : qualifiers) {
-      if (qualifier != null) builder.addQualifiers(ZeroCopyLiteralByteString.wrap(qualifier));
+      if (qualifier != null) builder.addQualifiers(HBaseZeroCopyByteString.wrap(qualifier));
     }
     return builder.build().toByteArray();
   }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java
index fcd0aa2..ee3ece2 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/FuzzyRowFilter.java
@@ -17,8 +17,8 @@
  */
 package org.apache.hadoop.hbase.filter;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
@@ -147,8 +147,8 @@ public class FuzzyRowFilter extends FilterBase {
       FilterProtos.FuzzyRowFilter.newBuilder();
     for (Pair<byte[], byte[]> fuzzyData : fuzzyKeysData) {
       BytesBytesPair.Builder bbpBuilder = BytesBytesPair.newBuilder();
-      bbpBuilder.setFirst(ZeroCopyLiteralByteString.wrap(fuzzyData.getFirst()));
-      bbpBuilder.setSecond(ZeroCopyLiteralByteString.wrap(fuzzyData.getSecond()));
+      bbpBuilder.setFirst(HBaseZeroCopyByteString.wrap(fuzzyData.getFirst()));
+      bbpBuilder.setSecond(HBaseZeroCopyByteString.wrap(fuzzyData.getSecond()));
       builder.addFuzzyKeysData(bbpBuilder);
     }
     return builder.build().toByteArray();
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java
index 65b6b1b..b938ec5 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/InclusiveStopFilter.java
@@ -21,6 +21,7 @@ package org.apache.hadoop.hbase.filter;
 
 import java.util.ArrayList;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
 import org.apache.hadoop.hbase.exceptions.DeserializationException;
@@ -29,7 +30,6 @@ import org.apache.hadoop.hbase.util.Bytes;
 
 import com.google.common.base.Preconditions;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * A Filter that stops after the given row.  There is no "RowStopFilter" because
@@ -86,7 +86,7 @@ public class InclusiveStopFilter extends FilterBase {
   public byte [] toByteArray() {
     FilterProtos.InclusiveStopFilter.Builder builder =
       FilterProtos.InclusiveStopFilter.newBuilder();
-    if (this.stopRowKey != null) builder.setStopRowKey(ZeroCopyLiteralByteString.wrap(this.stopRowKey));
+    if (this.stopRowKey != null) builder.setStopRowKey(HBaseZeroCopyByteString.wrap(this.stopRowKey));
     return builder.build().toByteArray();
   }
 
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/MultipleColumnPrefixFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/MultipleColumnPrefixFilter.java
index 961bed3..88ea67b 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/MultipleColumnPrefixFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/MultipleColumnPrefixFilter.java
@@ -18,8 +18,8 @@
 package org.apache.hadoop.hbase.filter;
 
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
@@ -114,7 +114,7 @@ public class MultipleColumnPrefixFilter extends FilterBase {
     FilterProtos.MultipleColumnPrefixFilter.Builder builder =
       FilterProtos.MultipleColumnPrefixFilter.newBuilder();
     for (byte [] element : sortedPrefixes) {
-      if (element != null) builder.addSortedPrefixes(ZeroCopyLiteralByteString.wrap(element));
+      if (element != null) builder.addSortedPrefixes(HBaseZeroCopyByteString.wrap(element));
     }
     return builder.build().toByteArray();
   }
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/PrefixFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/PrefixFilter.java
index c4eaa71..6cfed64 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/PrefixFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/PrefixFilter.java
@@ -20,8 +20,8 @@
 package org.apache.hadoop.hbase.filter;
 
 import com.google.common.base.Preconditions;
+import com.google.protobuf.HBaseZeroCopyByteString;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
@@ -91,7 +91,7 @@ public class PrefixFilter extends FilterBase {
   public byte [] toByteArray() {
     FilterProtos.PrefixFilter.Builder builder =
       FilterProtos.PrefixFilter.newBuilder();
-    if (this.prefix != null) builder.setPrefix(ZeroCopyLiteralByteString.wrap(this.prefix));
+    if (this.prefix != null) builder.setPrefix(HBaseZeroCopyByteString.wrap(this.prefix));
     return builder.build().toByteArray();
   }
 
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java
index de9830a..771efeb 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/SingleColumnValueFilter.java
@@ -22,6 +22,7 @@ package org.apache.hadoop.hbase.filter;
 import java.io.IOException;
 import java.util.ArrayList;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -40,7 +41,6 @@ import org.apache.hadoop.hbase.util.Bytes;
 
 import com.google.common.base.Preconditions;
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * This filter is used to filter cells based on value. It takes a {@link CompareFilter.CompareOp}
@@ -307,10 +307,10 @@ public class SingleColumnValueFilter extends FilterBase {
     FilterProtos.SingleColumnValueFilter.Builder builder =
       FilterProtos.SingleColumnValueFilter.newBuilder();
     if (this.columnFamily != null) {
-      builder.setColumnFamily(ZeroCopyLiteralByteString.wrap(this.columnFamily));
+      builder.setColumnFamily(HBaseZeroCopyByteString.wrap(this.columnFamily));
     }
     if (this.columnQualifier != null) {
-      builder.setColumnQualifier(ZeroCopyLiteralByteString.wrap(this.columnQualifier));
+      builder.setColumnQualifier(HBaseZeroCopyByteString.wrap(this.columnQualifier));
     }
     HBaseProtos.CompareType compareOp = CompareType.valueOf(this.compareOp.name());
     builder.setCompareOp(compareOp);
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/MasterCoprocessorRpcChannel.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/MasterCoprocessorRpcChannel.java
index eb41db0..97fdb6f 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/MasterCoprocessorRpcChannel.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/MasterCoprocessorRpcChannel.java
@@ -20,6 +20,7 @@ package org.apache.hadoop.hbase.ipc;
 
 import java.io.IOException;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -31,7 +32,6 @@ import org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServic
 
 import com.google.protobuf.Descriptors;
 import com.google.protobuf.Message;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * Provides clients with an RPC connection to call coprocessor endpoint {@link com.google.protobuf.Service}s
@@ -61,7 +61,7 @@ public class MasterCoprocessorRpcChannel extends CoprocessorRpcChannel{
 
     final ClientProtos.CoprocessorServiceCall call =
         ClientProtos.CoprocessorServiceCall.newBuilder()
-            .setRow(ZeroCopyLiteralByteString.wrap(HConstants.EMPTY_BYTE_ARRAY))
+            .setRow(HBaseZeroCopyByteString.wrap(HConstants.EMPTY_BYTE_ARRAY))
             .setServiceName(method.getService().getFullName())
             .setMethodName(method.getName())
             .setRequest(request.toByteString()).build();
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionCoprocessorRpcChannel.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionCoprocessorRpcChannel.java
index d66b945..3238348 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionCoprocessorRpcChannel.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/RegionCoprocessorRpcChannel.java
@@ -20,6 +20,7 @@ package org.apache.hadoop.hbase.ipc;
 
 import java.io.IOException;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -34,7 +35,6 @@ import org.apache.hadoop.hbase.util.Bytes;
 
 import com.google.protobuf.Descriptors;
 import com.google.protobuf.Message;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * Provides clients with an RPC connection to call coprocessor endpoint {@link com.google.protobuf.Service}s
@@ -76,7 +76,7 @@ public class RegionCoprocessorRpcChannel extends CoprocessorRpcChannel{
 
     final ClientProtos.CoprocessorServiceCall call =
         ClientProtos.CoprocessorServiceCall.newBuilder()
-            .setRow(ZeroCopyLiteralByteString.wrap(row))
+            .setRow(HBaseZeroCopyByteString.wrap(row))
             .setServiceName(method.getService().getFullName())
             .setMethodName(method.getName())
             .setRequest(request.toByteString()).build();
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
index 365ebf8..dbf856b 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/ProtobufUtil.java
@@ -36,6 +36,7 @@ import java.util.Map;
 import java.util.Map.Entry;
 import java.util.NavigableSet;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hbase.Cell;
@@ -138,7 +139,6 @@ import com.google.protobuf.RpcChannel;
 import com.google.protobuf.Service;
 import com.google.protobuf.ServiceException;
 import com.google.protobuf.TextFormat;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * Protobufs utility.
@@ -796,17 +796,17 @@ public final class ProtobufUtil {
       NameBytesPair.Builder attributeBuilder = NameBytesPair.newBuilder();
       for (Map.Entry<String, byte[]> attribute: attributes.entrySet()) {
         attributeBuilder.setName(attribute.getKey());
-        attributeBuilder.setValue(ZeroCopyLiteralByteString.wrap(attribute.getValue()));
+        attributeBuilder.setValue(HBaseZeroCopyByteString.wrap(attribute.getValue()));
         scanBuilder.addAttribute(attributeBuilder.build());
       }
     }
     byte[] startRow = scan.getStartRow();
     if (startRow != null && startRow.length > 0) {
-      scanBuilder.setStartRow(ZeroCopyLiteralByteString.wrap(startRow));
+      scanBuilder.setStartRow(HBaseZeroCopyByteString.wrap(startRow));
     }
     byte[] stopRow = scan.getStopRow();
     if (stopRow != null && stopRow.length > 0) {
-      scanBuilder.setStopRow(ZeroCopyLiteralByteString.wrap(stopRow));
+      scanBuilder.setStopRow(HBaseZeroCopyByteString.wrap(stopRow));
     }
     if (scan.hasFilter()) {
       scanBuilder.setFilter(ProtobufUtil.toFilter(scan.getFilter()));
@@ -815,12 +815,12 @@ public final class ProtobufUtil {
       Column.Builder columnBuilder = Column.newBuilder();
       for (Map.Entry<byte[],NavigableSet<byte []>>
           family: scan.getFamilyMap().entrySet()) {
-        columnBuilder.setFamily(ZeroCopyLiteralByteString.wrap(family.getKey()));
+        columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family.getKey()));
         NavigableSet<byte []> qualifiers = family.getValue();
         columnBuilder.clearQualifier();
         if (qualifiers != null && qualifiers.size() > 0) {
           for (byte [] qualifier: qualifiers) {
-            columnBuilder.addQualifier(ZeroCopyLiteralByteString.wrap(qualifier));
+            columnBuilder.addQualifier(HBaseZeroCopyByteString.wrap(qualifier));
           }
         }
         scanBuilder.addColumn(columnBuilder.build());
@@ -922,7 +922,7 @@ public final class ProtobufUtil {
       final Get get) throws IOException {
     ClientProtos.Get.Builder builder =
       ClientProtos.Get.newBuilder();
-    builder.setRow(ZeroCopyLiteralByteString.wrap(get.getRow()));
+    builder.setRow(HBaseZeroCopyByteString.wrap(get.getRow()));
     builder.setCacheBlocks(get.getCacheBlocks());
     builder.setMaxVersions(get.getMaxVersions());
     if (get.getFilter() != null) {
@@ -941,7 +941,7 @@ public final class ProtobufUtil {
       NameBytesPair.Builder attributeBuilder = NameBytesPair.newBuilder();
       for (Map.Entry<String, byte[]> attribute: attributes.entrySet()) {
         attributeBuilder.setName(attribute.getKey());
-        attributeBuilder.setValue(ZeroCopyLiteralByteString.wrap(attribute.getValue()));
+        attributeBuilder.setValue(HBaseZeroCopyByteString.wrap(attribute.getValue()));
         builder.addAttribute(attributeBuilder.build());
       }
     }
@@ -950,11 +950,11 @@ public final class ProtobufUtil {
       Map<byte[], NavigableSet<byte[]>> families = get.getFamilyMap();
       for (Map.Entry<byte[], NavigableSet<byte[]>> family: families.entrySet()) {
         NavigableSet<byte[]> qualifiers = family.getValue();
-        columnBuilder.setFamily(ZeroCopyLiteralByteString.wrap(family.getKey()));
+        columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family.getKey()));
         columnBuilder.clearQualifier();
         if (qualifiers != null && qualifiers.size() > 0) {
           for (byte[] qualifier: qualifiers) {
-            columnBuilder.addQualifier(ZeroCopyLiteralByteString.wrap(qualifier));
+            columnBuilder.addQualifier(HBaseZeroCopyByteString.wrap(qualifier));
           }
         }
         builder.addColumn(columnBuilder.build());
@@ -983,7 +983,7 @@ public final class ProtobufUtil {
    */
   public static MutationProto toMutation(final Increment increment,
       final MutationProto.Builder builder) {
-    builder.setRow(ZeroCopyLiteralByteString.wrap(increment.getRow()));
+    builder.setRow(HBaseZeroCopyByteString.wrap(increment.getRow()));
     builder.setMutateType(MutationType.INCREMENT);
     builder.setDurability(toDurability(increment.getDurability()));
     TimeRange timeRange = increment.getTimeRange();
@@ -997,15 +997,15 @@ public final class ProtobufUtil {
     ColumnValue.Builder columnBuilder = ColumnValue.newBuilder();
     QualifierValue.Builder valueBuilder = QualifierValue.newBuilder();
     for (Map.Entry<byte[], List<Cell>> family: increment.getFamilyCellMap().entrySet()) {
-      columnBuilder.setFamily(ZeroCopyLiteralByteString.wrap(family.getKey()));
+      columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family.getKey()));
       columnBuilder.clearQualifierValue();
       List<Cell> values = family.getValue();
       if (values != null && values.size() > 0) {
         for (Cell cell: values) {
           KeyValue kv = KeyValueUtil.ensureKeyValue(cell);
-          valueBuilder.setQualifier(ZeroCopyLiteralByteString.wrap(
+          valueBuilder.setQualifier(HBaseZeroCopyByteString.wrap(
               kv.getQualifierArray(), kv.getQualifierOffset(), kv.getQualifierLength()));
-          valueBuilder.setValue(ZeroCopyLiteralByteString.wrap(
+          valueBuilder.setValue(HBaseZeroCopyByteString.wrap(
               kv.getValueArray(), kv.getValueOffset(), kv.getValueLength()));
           columnBuilder.addQualifierValue(valueBuilder.build());
         }
@@ -1017,7 +1017,7 @@ public final class ProtobufUtil {
       NameBytesPair.Builder attributeBuilder = NameBytesPair.newBuilder();
       for (Map.Entry<String, byte[]> attribute : attributes.entrySet()) {
         attributeBuilder.setName(attribute.getKey());
-        attributeBuilder.setValue(ZeroCopyLiteralByteString.wrap(attribute.getValue()));
+        attributeBuilder.setValue(HBaseZeroCopyByteString.wrap(attribute.getValue()));
         builder.addAttribute(attributeBuilder.build());
       }
     }
@@ -1045,12 +1045,12 @@ public final class ProtobufUtil {
     QualifierValue.Builder valueBuilder = QualifierValue.newBuilder();
     for (Map.Entry<byte[],List<Cell>> family: mutation.getFamilyCellMap().entrySet()) {
       columnBuilder.clear();
-      columnBuilder.setFamily(ZeroCopyLiteralByteString.wrap(family.getKey()));
+      columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family.getKey()));
       for (Cell cell: family.getValue()) {
         KeyValue kv = KeyValueUtil.ensureKeyValue(cell);
-        valueBuilder.setQualifier(ZeroCopyLiteralByteString.wrap(
+        valueBuilder.setQualifier(HBaseZeroCopyByteString.wrap(
             kv.getQualifierArray(), kv.getQualifierOffset(), kv.getQualifierLength()));
-        valueBuilder.setValue(ZeroCopyLiteralByteString.wrap(
+        valueBuilder.setValue(HBaseZeroCopyByteString.wrap(
             kv.getValueArray(), kv.getValueOffset(), kv.getValueLength()));
         valueBuilder.setTimestamp(kv.getTimestamp());
         if (type == MutationType.DELETE) {
@@ -1104,7 +1104,7 @@ public final class ProtobufUtil {
    */
   private static MutationProto.Builder getMutationBuilderAndSetCommonFields(final MutationType type,
       final Mutation mutation, MutationProto.Builder builder) {
-    builder.setRow(ZeroCopyLiteralByteString.wrap(mutation.getRow()));
+    builder.setRow(HBaseZeroCopyByteString.wrap(mutation.getRow()));
     builder.setMutateType(type);
     builder.setDurability(toDurability(mutation.getDurability()));
     builder.setTimestamp(mutation.getTimeStamp());
@@ -1113,7 +1113,7 @@ public final class ProtobufUtil {
       NameBytesPair.Builder attributeBuilder = NameBytesPair.newBuilder();
       for (Map.Entry<String, byte[]> attribute: attributes.entrySet()) {
         attributeBuilder.setName(attribute.getKey());
-        attributeBuilder.setValue(ZeroCopyLiteralByteString.wrap(attribute.getValue()));
+        attributeBuilder.setValue(HBaseZeroCopyByteString.wrap(attribute.getValue()));
         builder.addAttribute(attributeBuilder.build());
       }
     }
@@ -1244,7 +1244,7 @@ public final class ProtobufUtil {
   public static ComparatorProtos.Comparator toComparator(ByteArrayComparable comparator) {
     ComparatorProtos.Comparator.Builder builder = ComparatorProtos.Comparator.newBuilder();
     builder.setName(comparator.getClass().getName());
-    builder.setSerializedComparator(ZeroCopyLiteralByteString.wrap(comparator.toByteArray()));
+    builder.setSerializedComparator(HBaseZeroCopyByteString.wrap(comparator.toByteArray()));
     return builder.build();
   }
 
@@ -1306,7 +1306,7 @@ public final class ProtobufUtil {
   public static FilterProtos.Filter toFilter(Filter filter) throws IOException {
     FilterProtos.Filter.Builder builder = FilterProtos.Filter.newBuilder();
     builder.setName(filter.getClass().getName());
-    builder.setSerializedFilter(ZeroCopyLiteralByteString.wrap(filter.toByteArray()));
+    builder.setSerializedFilter(HBaseZeroCopyByteString.wrap(filter.toByteArray()));
     return builder.build();
   }
 
@@ -1791,10 +1791,10 @@ public final class ProtobufUtil {
             AccessControlProtos.TablePermission.newBuilder();
         builder.setTableName(ProtobufUtil.toProtoTableName(tablePerm.getTableName()));
         if (tablePerm.hasFamily()) {
-          builder.setFamily(ZeroCopyLiteralByteString.wrap(tablePerm.getFamily()));
+          builder.setFamily(HBaseZeroCopyByteString.wrap(tablePerm.getFamily()));
         }
         if (tablePerm.hasQualifier()) {
-          builder.setQualifier(ZeroCopyLiteralByteString.wrap(tablePerm.getQualifier()));
+          builder.setQualifier(HBaseZeroCopyByteString.wrap(tablePerm.getQualifier()));
         }
         for (Permission.Action a : perm.getActions()) {
           builder.addAction(toPermissionAction(a));
@@ -1883,7 +1883,7 @@ public final class ProtobufUtil {
    */
   public static AccessControlProtos.UserPermission toUserPermission(UserPermission perm) {
     return AccessControlProtos.UserPermission.newBuilder()
-        .setUser(ZeroCopyLiteralByteString.wrap(perm.getUser()))
+        .setUser(HBaseZeroCopyByteString.wrap(perm.getUser()))
         .setPermission(toPermission(perm))
         .build();
   }
@@ -2155,8 +2155,8 @@ public final class ProtobufUtil {
    */
   public static AuthenticationProtos.Token toToken(Token<AuthenticationTokenIdentifier> token) {
     AuthenticationProtos.Token.Builder builder = AuthenticationProtos.Token.newBuilder();
-    builder.setIdentifier(ZeroCopyLiteralByteString.wrap(token.getIdentifier()));
-    builder.setPassword(ZeroCopyLiteralByteString.wrap(token.getPassword()));
+    builder.setIdentifier(HBaseZeroCopyByteString.wrap(token.getIdentifier()));
+    builder.setPassword(HBaseZeroCopyByteString.wrap(token.getPassword()));
     if (token.getService() != null) {
       builder.setService(ByteString.copyFromUtf8(token.getService().toString()));
     }
@@ -2253,16 +2253,16 @@ public final class ProtobufUtil {
     // Doing this is going to kill us if we do it for all data passed.
     // St.Ack 20121205
     CellProtos.Cell.Builder kvbuilder = CellProtos.Cell.newBuilder();
-    kvbuilder.setRow(ZeroCopyLiteralByteString.wrap(kv.getRowArray(), kv.getRowOffset(),
-      kv.getRowLength()));
-    kvbuilder.setFamily(ZeroCopyLiteralByteString.wrap(kv.getFamilyArray(),
-      kv.getFamilyOffset(), kv.getFamilyLength()));
-    kvbuilder.setQualifier(ZeroCopyLiteralByteString.wrap(kv.getQualifierArray(),
-      kv.getQualifierOffset(), kv.getQualifierLength()));
+    kvbuilder.setRow(HBaseZeroCopyByteString.wrap(kv.getRowArray(), kv.getRowOffset(),
+        kv.getRowLength()));
+    kvbuilder.setFamily(HBaseZeroCopyByteString.wrap(kv.getFamilyArray(),
+        kv.getFamilyOffset(), kv.getFamilyLength()));
+    kvbuilder.setQualifier(HBaseZeroCopyByteString.wrap(kv.getQualifierArray(),
+        kv.getQualifierOffset(), kv.getQualifierLength()));
     kvbuilder.setCellType(CellProtos.CellType.valueOf(kv.getTypeByte()));
     kvbuilder.setTimestamp(kv.getTimestamp());
-    kvbuilder.setValue(ZeroCopyLiteralByteString.wrap(kv.getValueArray(), kv.getValueOffset(),
-      kv.getValueLength()));
+    kvbuilder.setValue(HBaseZeroCopyByteString.wrap(kv.getValueArray(), kv.getValueOffset(),
+        kv.getValueLength()));
     return kvbuilder.build();
   }
 
@@ -2340,9 +2340,9 @@ public final class ProtobufUtil {
     // input / output paths are relative to the store dir
     // store dir is relative to region dir
     CompactionDescriptor.Builder builder = CompactionDescriptor.newBuilder()
-        .setTableName(ZeroCopyLiteralByteString.wrap(info.getTableName()))
-        .setEncodedRegionName(ZeroCopyLiteralByteString.wrap(info.getEncodedNameAsBytes()))
-        .setFamilyName(ZeroCopyLiteralByteString.wrap(family))
+        .setTableName(HBaseZeroCopyByteString.wrap(info.getTableName()))
+        .setEncodedRegionName(HBaseZeroCopyByteString.wrap(info.getEncodedNameAsBytes()))
+        .setFamilyName(HBaseZeroCopyByteString.wrap(family))
         .setStoreHomeDir(storeDir.getName()); //make relative
     for (Path inputPath : inputPaths) {
       builder.addCompactionInput(inputPath.getName()); //relative path
@@ -2419,8 +2419,8 @@ public final class ProtobufUtil {
 
   public static HBaseProtos.TableName toProtoTableName(TableName tableName) {
     return HBaseProtos.TableName.newBuilder()
-        .setNamespace(ZeroCopyLiteralByteString.wrap(tableName.getNamespace()))
-        .setQualifier(ZeroCopyLiteralByteString.wrap(tableName.getQualifier())).build();
+        .setNamespace(HBaseZeroCopyByteString.wrap(tableName.getNamespace()))
+        .setQualifier(HBaseZeroCopyByteString.wrap(tableName.getQualifier())).build();
   }
 
   public static TableName[] getTableNameArray(List<HBaseProtos.TableName> tableNamesList) {
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
index a18061a..04f7153 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/protobuf/RequestConverter.java
@@ -20,6 +20,7 @@ package org.apache.hadoop.hbase.protobuf;
 import java.io.IOException;
 import java.util.List;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.CellScannable;
 import org.apache.hadoop.hbase.DoNotRetryIOException;
@@ -101,7 +102,6 @@ import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.util.Triple;
 
 import com.google.protobuf.ByteString;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * Helper utility to build protocol buffer requests,
@@ -133,10 +133,10 @@ public final class RequestConverter {
     builder.setRegion(region);
 
     Column.Builder columnBuilder = Column.newBuilder();
-    columnBuilder.setFamily(ZeroCopyLiteralByteString.wrap(family));
+    columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
     ClientProtos.Get.Builder getBuilder =
       ClientProtos.Get.newBuilder();
-    getBuilder.setRow(ZeroCopyLiteralByteString.wrap(row));
+    getBuilder.setRow(HBaseZeroCopyByteString.wrap(row));
     getBuilder.addColumn(columnBuilder.build());
     getBuilder.setClosestRowBefore(true);
     builder.setGet(getBuilder.build());
@@ -181,14 +181,14 @@ public final class RequestConverter {
     builder.setRegion(region);
 
     MutationProto.Builder mutateBuilder = MutationProto.newBuilder();
-    mutateBuilder.setRow(ZeroCopyLiteralByteString.wrap(row));
+    mutateBuilder.setRow(HBaseZeroCopyByteString.wrap(row));
     mutateBuilder.setMutateType(MutationType.INCREMENT);
     mutateBuilder.setDurability(ProtobufUtil.toDurability(durability));
     ColumnValue.Builder columnBuilder = ColumnValue.newBuilder();
-    columnBuilder.setFamily(ZeroCopyLiteralByteString.wrap(family));
+    columnBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
     QualifierValue.Builder valueBuilder = QualifierValue.newBuilder();
-    valueBuilder.setValue(ZeroCopyLiteralByteString.wrap(Bytes.toBytes(amount)));
-    valueBuilder.setQualifier(ZeroCopyLiteralByteString.wrap(qualifier));
+    valueBuilder.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(amount)));
+    valueBuilder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
     columnBuilder.addQualifierValue(valueBuilder.build());
     mutateBuilder.addColumnValue(columnBuilder.build());
     builder.setMutation(mutateBuilder.build());
@@ -479,7 +479,7 @@ public final class RequestConverter {
     builder.setRegion(region);
     FamilyPath.Builder familyPathBuilder = FamilyPath.newBuilder();
     for (Pair<byte[], String> familyPath: familyPaths) {
-      familyPathBuilder.setFamily(ZeroCopyLiteralByteString.wrap(familyPath.getFirst()));
+      familyPathBuilder.setFamily(HBaseZeroCopyByteString.wrap(familyPath.getFirst()));
       familyPathBuilder.setPath(familyPath.getSecond());
       builder.addFamilyPath(familyPathBuilder.build());
     }
@@ -649,7 +649,7 @@ public final class RequestConverter {
    RegionSpecifier region = buildRegionSpecifier(
      RegionSpecifierType.REGION_NAME, regionName);
    builder.setRegion(region);
-   builder.addFamily(ZeroCopyLiteralByteString.wrap(family));
+   builder.addFamily(HBaseZeroCopyByteString.wrap(family));
    return builder.build();
  }
 
@@ -795,7 +795,7 @@ public final class RequestConverter {
      RegionSpecifierType.REGION_NAME, regionName);
    builder.setRegion(region);
    if (splitPoint != null) {
-     builder.setSplitPoint(ZeroCopyLiteralByteString.wrap(splitPoint));
+     builder.setSplitPoint(HBaseZeroCopyByteString.wrap(splitPoint));
    }
    return builder.build();
  }
@@ -835,7 +835,7 @@ public final class RequestConverter {
    builder.setRegion(region);
    builder.setMajor(major);
    if (family != null) {
-     builder.setFamily(ZeroCopyLiteralByteString.wrap(family));
+     builder.setFamily(HBaseZeroCopyByteString.wrap(family));
    }
    return builder.build();
  }
@@ -894,7 +894,7 @@ public final class RequestConverter {
   public static RegionSpecifier buildRegionSpecifier(
       final RegionSpecifierType type, final byte[] value) {
     RegionSpecifier.Builder regionBuilder = RegionSpecifier.newBuilder();
-    regionBuilder.setValue(ZeroCopyLiteralByteString.wrap(value));
+    regionBuilder.setValue(HBaseZeroCopyByteString.wrap(value));
     regionBuilder.setType(type);
     return regionBuilder.build();
   }
@@ -915,9 +915,9 @@ public final class RequestConverter {
       final ByteArrayComparable comparator,
       final CompareType compareType) throws IOException {
     Condition.Builder builder = Condition.newBuilder();
-    builder.setRow(ZeroCopyLiteralByteString.wrap(row));
-    builder.setFamily(ZeroCopyLiteralByteString.wrap(family));
-    builder.setQualifier(ZeroCopyLiteralByteString.wrap(qualifier));
+    builder.setRow(HBaseZeroCopyByteString.wrap(row));
+    builder.setFamily(HBaseZeroCopyByteString.wrap(family));
+    builder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
     builder.setComparator(ProtobufUtil.toComparator(comparator));
     builder.setCompareType(compareType);
     return builder.build();
@@ -949,7 +949,7 @@ public final class RequestConverter {
       final TableName tableName, final byte [] columnName) {
     DeleteColumnRequest.Builder builder = DeleteColumnRequest.newBuilder();
     builder.setTableName(ProtobufUtil.toProtoTableName((tableName)));
-    builder.setColumnName(ZeroCopyLiteralByteString.wrap(columnName));
+    builder.setColumnName(HBaseZeroCopyByteString.wrap(columnName));
     return builder.build();
   }
 
@@ -1089,7 +1089,7 @@ public final class RequestConverter {
     builder.setTableSchema(hTableDesc.convert());
     if (splitKeys != null) {
       for (byte [] splitKey : splitKeys) {
-        builder.addSplitKeys(ZeroCopyLiteralByteString.wrap(splitKey));
+        builder.addSplitKeys(HBaseZeroCopyByteString.wrap(splitKey));
       }
     }
     return builder.build();
@@ -1242,7 +1242,7 @@ public final class RequestConverter {
   public static GetLastFlushedSequenceIdRequest buildGetLastFlushedSequenceIdRequest(
       byte[] regionName) {
     return GetLastFlushedSequenceIdRequest.newBuilder().setRegionName(
-        ZeroCopyLiteralByteString.wrap(regionName)).build();
+        HBaseZeroCopyByteString.wrap(regionName)).build();
   }
 
   /**
@@ -1297,10 +1297,10 @@ public final class RequestConverter {
     permissionBuilder.setTableName(ProtobufUtil.toProtoTableName(tableName));
 
     if (family != null) {
-      permissionBuilder.setFamily(ZeroCopyLiteralByteString.wrap(family));
+      permissionBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
     }
     if (qualifier != null) {
-      permissionBuilder.setQualifier(ZeroCopyLiteralByteString.wrap(qualifier));
+      permissionBuilder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
     }
     ret.setType(AccessControlProtos.Permission.Type.Table)
        .setTablePermission(permissionBuilder);
@@ -1393,10 +1393,10 @@ public final class RequestConverter {
       permissionBuilder.setTableName(ProtobufUtil.toProtoTableName(tableName));
     }
     if (family != null) {
-      permissionBuilder.setFamily(ZeroCopyLiteralByteString.wrap(family));
+      permissionBuilder.setFamily(HBaseZeroCopyByteString.wrap(family));
     }
     if (qualifier != null) {
-      permissionBuilder.setQualifier(ZeroCopyLiteralByteString.wrap(qualifier));
+      permissionBuilder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
     }
     ret.setType(AccessControlProtos.Permission.Type.Table)
        .setTablePermission(permissionBuilder);
diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java
index 93a5515..1f75412 100644
--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java
+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java
@@ -35,6 +35,7 @@ import java.util.Properties;
 import javax.security.auth.login.AppConfigurationEntry;
 import javax.security.auth.login.AppConfigurationEntry.LoginModuleControlFlag;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.lang.StringUtils;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -70,7 +71,6 @@ import org.apache.zookeeper.proto.SetDataRequest;
 import org.apache.zookeeper.server.ZooKeeperSaslServer;
 
 import com.google.protobuf.InvalidProtocolBufferException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * Internal HBase utility class for ZooKeeper.
@@ -1941,7 +1941,7 @@ public class ZKUtil {
       for (Map.Entry<byte[], Long> e : storeSequenceIds.entrySet()){
         byte[] columnFamilyName = e.getKey();
         Long curSeqId = e.getValue();
-        storeSequenceIdBuilder.setFamilyName(ZeroCopyLiteralByteString.wrap(columnFamilyName));
+        storeSequenceIdBuilder.setFamilyName(HBaseZeroCopyByteString.wrap(columnFamilyName));
         storeSequenceIdBuilder.setSequenceId(curSeqId);
         regionSequenceIdsBuilder.addStoreSequenceId(storeSequenceIdBuilder.build());
         storeSequenceIdBuilder.clear();
diff --git a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java
index dcdb8fd..7ee4476 100644
--- a/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java
+++ b/hbase-client/src/test/java/org/apache/hadoop/hbase/client/TestClientNoCluster.java
@@ -33,6 +33,7 @@ import java.util.concurrent.Executors;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.lang.NotImplementedException;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -84,7 +85,6 @@ import com.google.common.base.Stopwatch;
 import com.google.protobuf.ByteString;
 import com.google.protobuf.RpcController;
 import com.google.protobuf.ServiceException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * Test client behavior w/o setting up a cluster.
@@ -510,7 +510,7 @@ public class TestClientNoCluster extends Configured implements Tool {
       if (max <= 0) break;
       if (++count > max) break;
       HRegionInfo hri = e.getValue().getFirst();
-      ByteString row = ZeroCopyLiteralByteString.wrap(hri.getRegionName());
+      ByteString row = HBaseZeroCopyByteString.wrap(hri.getRegionName());
       resultBuilder.clear();
       resultBuilder.addCell(getRegionInfo(row, hri));
       resultBuilder.addCell(getServer(row, e.getValue().getSecond()));
@@ -565,11 +565,11 @@ public class TestClientNoCluster extends Configured implements Tool {
   }
 
   private final static ByteString CATALOG_FAMILY_BYTESTRING =
-      ZeroCopyLiteralByteString.wrap(HConstants.CATALOG_FAMILY);
+      HBaseZeroCopyByteString.wrap(HConstants.CATALOG_FAMILY);
   private final static ByteString REGIONINFO_QUALIFIER_BYTESTRING =
-      ZeroCopyLiteralByteString.wrap(HConstants.REGIONINFO_QUALIFIER);
+      HBaseZeroCopyByteString.wrap(HConstants.REGIONINFO_QUALIFIER);
   private final static ByteString SERVER_QUALIFIER_BYTESTRING =
-      ZeroCopyLiteralByteString.wrap(HConstants.SERVER_QUALIFIER);
+      HBaseZeroCopyByteString.wrap(HConstants.SERVER_QUALIFIER);
 
   static CellProtos.Cell.Builder getBaseCellBuilder(final ByteString row) {
     CellProtos.Cell.Builder cellBuilder = CellProtos.Cell.newBuilder();
@@ -582,7 +582,7 @@ public class TestClientNoCluster extends Configured implements Tool {
   static CellProtos.Cell getRegionInfo(final ByteString row, final HRegionInfo hri) {
     CellProtos.Cell.Builder cellBuilder = getBaseCellBuilder(row);
     cellBuilder.setQualifier(REGIONINFO_QUALIFIER_BYTESTRING);
-    cellBuilder.setValue(ZeroCopyLiteralByteString.wrap(hri.toByteArray()));
+    cellBuilder.setValue(HBaseZeroCopyByteString.wrap(hri.toByteArray()));
     return cellBuilder.build();
   }
 
@@ -595,9 +595,9 @@ public class TestClientNoCluster extends Configured implements Tool {
 
   static CellProtos.Cell getStartCode(final ByteString row) {
     CellProtos.Cell.Builder cellBuilder = getBaseCellBuilder(row);
-    cellBuilder.setQualifier(ZeroCopyLiteralByteString.wrap(HConstants.STARTCODE_QUALIFIER));
+    cellBuilder.setQualifier(HBaseZeroCopyByteString.wrap(HConstants.STARTCODE_QUALIFIER));
     // TODO:
-    cellBuilder.setValue(ZeroCopyLiteralByteString.wrap(Bytes.toBytes(META_SERVERNAME.getStartcode())));
+    cellBuilder.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(META_SERVERNAME.getStartcode())));
     return cellBuilder.build();
   }
 
diff --git a/hbase-protocol/src/main/java/com/google/protobuf/HBaseZeroCopyByteString.java b/hbase-protocol/src/main/java/com/google/protobuf/HBaseZeroCopyByteString.java
new file mode 100644
index 0000000..55933a0
--- /dev/null
+++ b/hbase-protocol/src/main/java/com/google/protobuf/HBaseZeroCopyByteString.java
@@ -0,0 +1,63 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.protobuf;  // This is a lie.
+
+/**
+ * Helper class to extract byte arrays from {@link ByteString} without copy.
+ * <p>
+ * Without this protobufs would force us to copy every single byte array out
+ * of the objects de-serialized from the wire (which already do one copy, on
+ * top of the copies the JVM does to go from kernel buffer to C buffer and
+ * from C buffer to JVM buffer).
+ *
+ * @since 0.96.1
+ */
+public final class HBaseZeroCopyByteString extends LiteralByteString {
+  // Gotten from AsyncHBase code base with permission.
+  /** Private constructor so this class cannot be instantiated. */
+  private HBaseZeroCopyByteString() {
+    super(null);
+    throw new UnsupportedOperationException("Should never be here.");
+  }
+
+  /**
+   * Wraps a byte array in a {@link ByteString} without copying it.
+   */
+  public static ByteString wrap(final byte[] array) {
+    return new LiteralByteString(array);
+  }
+
+  /**
+   * Wraps a subset of a byte array in a {@link ByteString} without copying it.
+   */
+  public static ByteString wrap(final byte[] array, int offset, int length) {
+    return new BoundedByteString(array, offset, length);
+  }
+
+  // TODO:
+  // ZeroCopyLiteralByteString.wrap(this.buf, 0, this.count);
+
+  /**
+   * Extracts the byte array from the given {@link ByteString} without copy.
+   * @param buf A buffer from which to extract the array.  This buffer must be
+   * actually an instance of a {@code LiteralByteString}.
+   */
+  public static byte[] zeroCopyGetBytes(final LiteralByteString buf) {
+    return buf.bytes;
+  }
+}
diff --git a/hbase-protocol/src/main/java/com/google/protobuf/ZeroCopyLiteralByteString.java b/hbase-protocol/src/main/java/com/google/protobuf/ZeroCopyLiteralByteString.java
deleted file mode 100644
index c57f1a7..0000000
--- a/hbase-protocol/src/main/java/com/google/protobuf/ZeroCopyLiteralByteString.java
+++ /dev/null
@@ -1,63 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package com.google.protobuf;  // This is a lie.
-
-/**
- * Helper class to extract byte arrays from {@link ByteString} without copy.
- * <p>
- * Without this protobufs would force us to copy every single byte array out
- * of the objects de-serialized from the wire (which already do one copy, on
- * top of the copies the JVM does to go from kernel buffer to C buffer and
- * from C buffer to JVM buffer).
- *
- * @since 0.96.1
- */
-public final class ZeroCopyLiteralByteString extends LiteralByteString {
-  // Gotten from AsyncHBase code base with permission.
-  /** Private constructor so this class cannot be instantiated. */
-  private ZeroCopyLiteralByteString() {
-    super(null);
-    throw new UnsupportedOperationException("Should never be here.");
-  }
-
-  /**
-   * Wraps a byte array in a {@link ByteString} without copying it.
-   */
-  public static ByteString wrap(final byte[] array) {
-    return new LiteralByteString(array);
-  }
-
-  /**
-   * Wraps a subset of a byte array in a {@link ByteString} without copying it.
-   */
-  public static ByteString wrap(final byte[] array, int offset, int length) {
-    return new BoundedByteString(array, offset, length);
-  }
-
-  // TODO:
-  // ZeroCopyLiteralByteString.wrap(this.buf, 0, this.count);
-
-  /**
-   * Extracts the byte array from the given {@link ByteString} without copy.
-   * @param buf A buffer from which to extract the array.  This buffer must be
-   * actually an instance of a {@code LiteralByteString}.
-   */
-  public static byte[] zeroCopyGetBytes(final LiteralByteString buf) {
-    return buf.bytes;
-  }
-}
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java
index 1a2d7ed..7ed9f6b 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/Reference.java
@@ -24,6 +24,7 @@ import java.io.DataInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.fs.FSDataOutputStream;
 import org.apache.hadoop.fs.FileSystem;
@@ -33,9 +34,6 @@ import org.apache.hadoop.hbase.protobuf.ProtobufUtil;
 import org.apache.hadoop.hbase.protobuf.generated.FSProtos;
 import org.apache.hadoop.hbase.util.Bytes;
 
-import com.google.protobuf.ByteString;
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 /**
  * A reference to the top or bottom half of a store file where 'bottom' is the first half
  * of the file containing the keys that sort lowest and 'top' is the second half
@@ -195,7 +193,7 @@ public class Reference {
     FSProtos.Reference.Builder builder = FSProtos.Reference.newBuilder();
     builder.setRange(isTopFileRegion(getFileRegion())?
       FSProtos.Reference.Range.TOP: FSProtos.Reference.Range.BOTTOM);
-    builder.setSplitkey(ZeroCopyLiteralByteString.wrap(getSplitKey()));
+    builder.setSplitkey(HBaseZeroCopyByteString.wrap(getSplitKey()));
     return builder.build();
   }
 
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java
index acb202b..021ffe6 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/io/hfile/HFile.java
@@ -40,6 +40,7 @@ import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -70,7 +71,6 @@ import org.apache.hadoop.io.Writable;
 
 import com.google.common.base.Preconditions;
 import com.google.common.collect.Lists;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * File format for hbase.
@@ -763,8 +763,8 @@ public class HFile {
       HFileProtos.FileInfoProto.Builder builder = HFileProtos.FileInfoProto.newBuilder();
       for (Map.Entry<byte [], byte[]> e: this.map.entrySet()) {
         HBaseProtos.BytesBytesPair.Builder bbpBuilder = HBaseProtos.BytesBytesPair.newBuilder();
-        bbpBuilder.setFirst(ZeroCopyLiteralByteString.wrap(e.getKey()));
-        bbpBuilder.setSecond(ZeroCopyLiteralByteString.wrap(e.getValue()));
+        bbpBuilder.setFirst(HBaseZeroCopyByteString.wrap(e.getKey()));
+        bbpBuilder.setSecond(HBaseZeroCopyByteString.wrap(e.getValue()));
         builder.addMapEntry(bbpBuilder.build());
       }
       out.write(ProtobufUtil.PB_MAGIC);
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java
index 70a6205..6efa1c3 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/protobuf/ReplicationProtbufUtil.java
@@ -28,6 +28,7 @@ import java.util.Map;
 import java.util.NavigableMap;
 import java.util.UUID;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.Cell;
 import org.apache.hadoop.hbase.CellScanner;
@@ -44,7 +45,6 @@ import org.apache.hadoop.hbase.regionserver.wal.WALEdit;
 import org.apache.hadoop.hbase.util.Pair;
 
 import com.google.protobuf.ServiceException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 @InterfaceAudience.Private
 public class ReplicationProtbufUtil {
@@ -89,8 +89,8 @@ public class ReplicationProtbufUtil {
       WALProtos.WALKey.Builder keyBuilder = entryBuilder.getKeyBuilder();
       HLogKey key = entry.getKey();
       keyBuilder.setEncodedRegionName(
-        ZeroCopyLiteralByteString.wrap(key.getEncodedRegionName()));
-      keyBuilder.setTableName(ZeroCopyLiteralByteString.wrap(key.getTablename().getName()));
+        HBaseZeroCopyByteString.wrap(key.getEncodedRegionName()));
+      keyBuilder.setTableName(HBaseZeroCopyByteString.wrap(key.getTablename().getName()));
       keyBuilder.setLogSequenceNumber(key.getLogSeqNum());
       keyBuilder.setWriteTime(key.getWriteTime());
       for(UUID clusterId : key.getClusterIds()) {
@@ -102,7 +102,7 @@ public class ReplicationProtbufUtil {
       NavigableMap<byte[], Integer> scopes = key.getScopes();
       if (scopes != null && !scopes.isEmpty()) {
         for (Map.Entry<byte[], Integer> scope: scopes.entrySet()) {
-          scopeBuilder.setFamily(ZeroCopyLiteralByteString.wrap(scope.getKey()));
+          scopeBuilder.setFamily(HBaseZeroCopyByteString.wrap(scope.getKey()));
           WALProtos.ScopeType scopeType =
               WALProtos.ScopeType.valueOf(scope.getValue().intValue());
           scopeBuilder.setScopeType(scopeType);
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
index 240e6b3..5f43790 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java
@@ -49,6 +49,7 @@ import java.util.concurrent.locks.ReentrantReadWriteLock;
 
 import javax.management.ObjectName;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -232,7 +233,6 @@ import com.google.protobuf.Message;
 import com.google.protobuf.RpcController;
 import com.google.protobuf.ServiceException;
 import com.google.protobuf.TextFormat;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * HRegionServer makes a set of HRegions available to clients. It checks in with
@@ -1267,7 +1267,7 @@ public class HRegionServer implements ClientProtos.ClientService.BlockingInterfa
     RegionLoad.Builder regionLoad = RegionLoad.newBuilder();
     RegionSpecifier.Builder regionSpecifier = RegionSpecifier.newBuilder();
     regionSpecifier.setType(RegionSpecifierType.REGION_NAME);
-    regionSpecifier.setValue(ZeroCopyLiteralByteString.wrap(name));
+    regionSpecifier.setValue(HBaseZeroCopyByteString.wrap(name));
     regionLoad.setRegionSpecifier(regionSpecifier.build())
       .setStores(stores)
       .setStorefiles(storefiles)
@@ -3902,7 +3902,7 @@ public class HRegionServer implements ClientProtos.ClientService.BlockingInterfa
       RollWALWriterResponse.Builder builder = RollWALWriterResponse.newBuilder();
       if (regionsToFlush != null) {
         for (byte[] region: regionsToFlush) {
-          builder.addRegionToFlush(ZeroCopyLiteralByteString.wrap(region));
+          builder.addRegionToFlush(HBaseZeroCopyByteString.wrap(region));
         }
       }
       return builder.build();
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogKey.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogKey.java
index 6fb2124..dd630f9 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogKey.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/HLogKey.java
@@ -31,6 +31,7 @@ import java.util.NavigableMap;
 import java.util.TreeMap;
 import java.util.UUID;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.classification.InterfaceAudience;
@@ -46,7 +47,6 @@ import org.apache.hadoop.io.WritableComparable;
 import org.apache.hadoop.io.WritableUtils;
 
 import com.google.protobuf.ByteString;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * A Key for an entry in the change log.
@@ -425,8 +425,8 @@ public class HLogKey implements WritableComparable<HLogKey> {
       WALCellCodec.ByteStringCompressor compressor) throws IOException {
     WALKey.Builder builder = WALKey.newBuilder();
     if (compressionContext == null) {
-      builder.setEncodedRegionName(ZeroCopyLiteralByteString.wrap(this.encodedRegionName));
-      builder.setTableName(ZeroCopyLiteralByteString.wrap(this.tablename.getName()));
+      builder.setEncodedRegionName(HBaseZeroCopyByteString.wrap(this.encodedRegionName));
+      builder.setTableName(HBaseZeroCopyByteString.wrap(this.tablename.getName()));
     } else {
       builder.setEncodedRegionName(
           compressor.compress(this.encodedRegionName, compressionContext.regionDict));
@@ -443,7 +443,7 @@ public class HLogKey implements WritableComparable<HLogKey> {
     }
     if (scopes != null) {
       for (Map.Entry<byte[], Integer> e : scopes.entrySet()) {
-        ByteString family = (compressionContext == null) ? ZeroCopyLiteralByteString.wrap(e.getKey())
+        ByteString family = (compressionContext == null) ? HBaseZeroCopyByteString.wrap(e.getKey())
             : compressor.compress(e.getKey(), compressionContext.familyDict);
         builder.addScopes(FamilyScope.newBuilder()
             .setFamily(family).setScopeType(ScopeType.valueOf(e.getValue())));
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellModel.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellModel.java
index 205fa1c..c01359d 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellModel.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellModel.java
@@ -28,6 +28,7 @@ import javax.xml.bind.annotation.XmlAttribute;
 import javax.xml.bind.annotation.XmlRootElement;
 import javax.xml.bind.annotation.XmlValue;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.KeyValue;
@@ -35,8 +36,6 @@ import org.apache.hadoop.hbase.rest.ProtobufMessageHandler;
 import org.apache.hadoop.hbase.rest.protobuf.generated.CellMessage.Cell;
 import org.codehaus.jackson.annotate.JsonProperty;
 
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 /**
  * Representation of a cell. A cell is a single value associated a column and
  * optional qualifier, and either the timestamp when it was stored or the user-
@@ -185,8 +184,8 @@ public class CellModel implements ProtobufMessageHandler, Serializable {
   @Override
   public byte[] createProtobufOutput() {
     Cell.Builder builder = Cell.newBuilder();
-    builder.setColumn(ZeroCopyLiteralByteString.wrap(getColumn()));
-    builder.setData(ZeroCopyLiteralByteString.wrap(getValue()));
+    builder.setColumn(HBaseZeroCopyByteString.wrap(getColumn()));
+    builder.setData(HBaseZeroCopyByteString.wrap(getValue()));
     if (hasUserTimestamp()) {
       builder.setTimestamp(getTimestamp());
     }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java
index 2ad441f..5261484 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/CellSetModel.java
@@ -29,14 +29,13 @@ import javax.xml.bind.annotation.XmlAccessorType;
 import javax.xml.bind.annotation.XmlElement;
 import javax.xml.bind.annotation.XmlRootElement;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.rest.ProtobufMessageHandler;
 import org.apache.hadoop.hbase.rest.protobuf.generated.CellMessage.Cell;
 import org.apache.hadoop.hbase.rest.protobuf.generated.CellSetMessage.CellSet;
 
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 /**
  * Representation of a grouping of cells. May contain cells from more than
  * one row. Encapsulates RowModel and CellModel models.
@@ -115,11 +114,11 @@ public class CellSetModel implements Serializable, ProtobufMessageHandler {
     CellSet.Builder builder = CellSet.newBuilder();
     for (RowModel row: getRows()) {
       CellSet.Row.Builder rowBuilder = CellSet.Row.newBuilder();
-      rowBuilder.setKey(ZeroCopyLiteralByteString.wrap(row.getKey()));
+      rowBuilder.setKey(HBaseZeroCopyByteString.wrap(row.getKey()));
       for (CellModel cell: row.getCells()) {
         Cell.Builder cellBuilder = Cell.newBuilder();
-        cellBuilder.setColumn(ZeroCopyLiteralByteString.wrap(cell.getColumn()));
-        cellBuilder.setData(ZeroCopyLiteralByteString.wrap(cell.getValue()));
+        cellBuilder.setColumn(HBaseZeroCopyByteString.wrap(cell.getColumn()));
+        cellBuilder.setData(HBaseZeroCopyByteString.wrap(cell.getValue()));
         if (cell.hasUserTimestamp()) {
           cellBuilder.setTimestamp(cell.getTimestamp());
         }
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java
index 92b9a1a..e26a073 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/ScannerModel.java
@@ -32,6 +32,7 @@ import javax.xml.bind.annotation.XmlAttribute;
 import javax.xml.bind.annotation.XmlElement;
 import javax.xml.bind.annotation.XmlRootElement;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.client.Scan;
@@ -43,7 +44,6 @@ import org.apache.hadoop.hbase.util.Base64;
 import org.apache.hadoop.hbase.util.Bytes;
 
 import com.google.protobuf.ByteString;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 import com.sun.jersey.api.json.JSONConfiguration;
 import com.sun.jersey.api.json.JSONJAXBContext;
 import com.sun.jersey.api.json.JSONMarshaller;
@@ -708,13 +708,13 @@ public class ScannerModel implements ProtobufMessageHandler, Serializable {
   public byte[] createProtobufOutput() {
     Scanner.Builder builder = Scanner.newBuilder();
     if (!Bytes.equals(startRow, HConstants.EMPTY_START_ROW)) {
-      builder.setStartRow(ZeroCopyLiteralByteString.wrap(startRow));
+      builder.setStartRow(HBaseZeroCopyByteString.wrap(startRow));
     }
     if (!Bytes.equals(endRow, HConstants.EMPTY_START_ROW)) {
-      builder.setEndRow(ZeroCopyLiteralByteString.wrap(endRow));
+      builder.setEndRow(HBaseZeroCopyByteString.wrap(endRow));
     }
     for (byte[] column: columns) {
-      builder.addColumns(ZeroCopyLiteralByteString.wrap(column));
+      builder.addColumns(HBaseZeroCopyByteString.wrap(column));
     }
     if (startTime != 0) {
       builder.setStartTime(startTime);
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/StorageClusterStatusModel.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/StorageClusterStatusModel.java
index 35a8cd8..081e9ce 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/StorageClusterStatusModel.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/StorageClusterStatusModel.java
@@ -29,13 +29,12 @@ import javax.xml.bind.annotation.XmlElement;
 import javax.xml.bind.annotation.XmlElementWrapper;
 import javax.xml.bind.annotation.XmlRootElement;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.rest.ProtobufMessageHandler;
 import org.apache.hadoop.hbase.rest.protobuf.generated.StorageClusterStatusMessage.StorageClusterStatus;
 import org.apache.hadoop.hbase.util.Bytes;
 
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 /**
  * Representation of the status of a storage cluster:
  * <p>
@@ -719,7 +718,7 @@ public class StorageClusterStatusModel
       for (Node.Region region: node.regions) {
         StorageClusterStatus.Region.Builder regionBuilder =
           StorageClusterStatus.Region.newBuilder();
-        regionBuilder.setName(ZeroCopyLiteralByteString.wrap(region.name));
+        regionBuilder.setName(HBaseZeroCopyByteString.wrap(region.name));
         regionBuilder.setStores(region.stores);
         regionBuilder.setStorefiles(region.storefiles);
         regionBuilder.setStorefileSizeMB(region.storefileSizeMB);
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/TableInfoModel.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/TableInfoModel.java
index 6a395ff..63502e1 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/TableInfoModel.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/rest/model/TableInfoModel.java
@@ -28,12 +28,11 @@ import javax.xml.bind.annotation.XmlAttribute;
 import javax.xml.bind.annotation.XmlElement;
 import javax.xml.bind.annotation.XmlRootElement;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.hbase.rest.ProtobufMessageHandler;
 import org.apache.hadoop.hbase.rest.protobuf.generated.TableInfoMessage.TableInfo;
 
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 /**
  * Representation of a list of table regions. 
  * 
@@ -135,8 +134,8 @@ public class TableInfoModel implements Serializable, ProtobufMessageHandler {
       TableInfo.Region.Builder regionBuilder = TableInfo.Region.newBuilder();
       regionBuilder.setName(aRegion.getName());
       regionBuilder.setId(aRegion.getId());
-      regionBuilder.setStartKey(ZeroCopyLiteralByteString.wrap(aRegion.getStartKey()));
-      regionBuilder.setEndKey(ZeroCopyLiteralByteString.wrap(aRegion.getEndKey()));
+      regionBuilder.setStartKey(HBaseZeroCopyByteString.wrap(aRegion.getStartKey()));
+      regionBuilder.setEndKey(HBaseZeroCopyByteString.wrap(aRegion.getEndKey()));
       regionBuilder.setLocation(aRegion.getLocation());
       builder.addRegions(regionBuilder);
     }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
index eb4b3a2..3cc73c1 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestCoprocessorEndpoint.java
@@ -30,6 +30,7 @@ import java.util.Map;
 import java.util.NavigableMap;
 import java.util.TreeMap;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
@@ -59,7 +60,6 @@ import org.junit.experimental.categories.Category;
 
 import com.google.protobuf.RpcController;
 import com.google.protobuf.ServiceException;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * TestEndpoint: test cases to verify coprocessor Endpoint
@@ -125,9 +125,9 @@ public class TestCoprocessorEndpoint {
               new BlockingRpcCallback<ColumnAggregationProtos.SumResponse>();
           ColumnAggregationProtos.SumRequest.Builder builder =
             ColumnAggregationProtos.SumRequest.newBuilder();
-          builder.setFamily(ZeroCopyLiteralByteString.wrap(family));
+          builder.setFamily(HBaseZeroCopyByteString.wrap(family));
           if (qualifier != null && qualifier.length > 0) {
-            builder.setQualifier(ZeroCopyLiteralByteString.wrap(qualifier));
+            builder.setQualifier(HBaseZeroCopyByteString.wrap(qualifier));
           }
           instance.sum(null, builder.build(), rpcCallback);
           return rpcCallback.get().getSum();
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java
index dd42368..63750b5 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/coprocessor/TestRowProcessorEndpoint.java
@@ -33,6 +33,7 @@ import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.Cell;
 import org.apache.hadoop.hbase.CellUtil;
@@ -70,7 +71,6 @@ import org.junit.Test;
 import org.junit.experimental.categories.Category;
 
 import com.google.protobuf.Message;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 import com.sun.org.apache.commons.logging.Log;
 import com.sun.org.apache.commons.logging.LogFactory;
 
@@ -362,7 +362,7 @@ public class TestRowProcessorEndpoint {
       public IncCounterProcessorRequest getRequestData() throws IOException {
         IncCounterProcessorRequest.Builder builder = IncCounterProcessorRequest.newBuilder();
         builder.setCounter(counter);
-        builder.setRow(ZeroCopyLiteralByteString.wrap(row));
+        builder.setRow(HBaseZeroCopyByteString.wrap(row));
         return builder.build();
       }
 
@@ -441,8 +441,8 @@ public class TestRowProcessorEndpoint {
       public FriendsOfFriendsProcessorRequest getRequestData() throws IOException {
         FriendsOfFriendsProcessorRequest.Builder builder =
             FriendsOfFriendsProcessorRequest.newBuilder();
-        builder.setPerson(ZeroCopyLiteralByteString.wrap(person));
-        builder.setRow(ZeroCopyLiteralByteString.wrap(row));
+        builder.setPerson(HBaseZeroCopyByteString.wrap(person));
+        builder.setRow(HBaseZeroCopyByteString.wrap(row));
         builder.addAllResult(result);
         FriendsOfFriendsProcessorRequest f = builder.build();
         return f;
@@ -546,8 +546,8 @@ public class TestRowProcessorEndpoint {
       @Override
       public RowSwapProcessorRequest getRequestData() throws IOException {
         RowSwapProcessorRequest.Builder builder = RowSwapProcessorRequest.newBuilder();
-        builder.setRow1(ZeroCopyLiteralByteString.wrap(row1));
-        builder.setRow2(ZeroCopyLiteralByteString.wrap(row2));
+        builder.setRow1(HBaseZeroCopyByteString.wrap(row1));
+        builder.setRow2(HBaseZeroCopyByteString.wrap(row2));
         return builder.build();
       }
 
@@ -606,7 +606,7 @@ public class TestRowProcessorEndpoint {
       @Override
       public TimeoutProcessorRequest getRequestData() throws IOException {
         TimeoutProcessorRequest.Builder builder = TimeoutProcessorRequest.newBuilder();
-        builder.setRow(ZeroCopyLiteralByteString.wrap(row));
+        builder.setRow(HBaseZeroCopyByteString.wrap(row));
         return builder.build();
       }
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/protobuf/TestProtobufUtil.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/protobuf/TestProtobufUtil.java
index 51fceb5..dc3c3ad 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/protobuf/TestProtobufUtil.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/protobuf/TestProtobufUtil.java
@@ -22,6 +22,7 @@ import static org.junit.Assert.assertEquals;
 
 import java.io.IOException;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.hbase.SmallTests;
 import org.apache.hadoop.hbase.client.Append;
 import org.apache.hadoop.hbase.client.Delete;
@@ -42,7 +43,6 @@ import org.junit.Test;
 import org.junit.experimental.categories.Category;
 
 import com.google.protobuf.ByteString;
-import com.google.protobuf.ZeroCopyLiteralByteString;
 
 /**
  * Class to test ProtobufUtil.
@@ -54,12 +54,12 @@ public class TestProtobufUtil {
     NameBytesPair.Builder builder = NameBytesPair.newBuilder();
     final String omg = "OMG!!!";
     builder.setName("java.io.IOException");
-    builder.setValue(ZeroCopyLiteralByteString.wrap(Bytes.toBytes(omg)));
+    builder.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(omg)));
     Throwable t = ProtobufUtil.toException(builder.build());
     assertEquals(omg, t.getMessage());
     builder.clear();
     builder.setName("org.apache.hadoop.ipc.RemoteException");
-    builder.setValue(ZeroCopyLiteralByteString.wrap(Bytes.toBytes(omg)));
+    builder.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(omg)));
     t = ProtobufUtil.toException(builder.build());
     assertEquals(omg, t.getMessage());
   }
@@ -203,10 +203,10 @@ public class TestProtobufUtil {
     valueBuilder.setFamily(ByteString.copyFromUtf8("f1"));
     QualifierValue.Builder qualifierBuilder = QualifierValue.newBuilder();
     qualifierBuilder.setQualifier(ByteString.copyFromUtf8("c1"));
-    qualifierBuilder.setValue(ZeroCopyLiteralByteString.wrap(Bytes.toBytes(11L)));
+    qualifierBuilder.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(11L)));
     valueBuilder.addQualifierValue(qualifierBuilder.build());
     qualifierBuilder.setQualifier(ByteString.copyFromUtf8("c2"));
-    qualifierBuilder.setValue(ZeroCopyLiteralByteString.wrap(Bytes.toBytes(22L)));
+    qualifierBuilder.setValue(HBaseZeroCopyByteString.wrap(Bytes.toBytes(22L)));
     valueBuilder.addQualifierValue(qualifierBuilder.build());
     mutateBuilder.addColumnValue(valueBuilder.build());
 
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java
index 3932267..1bce97d 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java
@@ -23,6 +23,7 @@ import static org.junit.Assert.*;
 
 import java.io.IOException;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.HConstants;
@@ -42,7 +43,7 @@ import org.mockito.Mockito;
 
 import com.google.protobuf.ByteString;
 import com.google.protobuf.Message;
-import com.google.protobuf.ZeroCopyLiteralByteString;
+
 /**
  * Tests that verify certain RPCs get a higher QoS.
  */
@@ -70,12 +71,12 @@ public class TestPriorityRpc {
     GetRequest.Builder getRequestBuilder = GetRequest.newBuilder();
     RegionSpecifier.Builder regionSpecifierBuilder = RegionSpecifier.newBuilder();
     regionSpecifierBuilder.setType(RegionSpecifierType.REGION_NAME);
-    ByteString name = ZeroCopyLiteralByteString.wrap(HRegionInfo.FIRST_META_REGIONINFO.getRegionName());
+    ByteString name = HBaseZeroCopyByteString.wrap(HRegionInfo.FIRST_META_REGIONINFO.getRegionName());
     regionSpecifierBuilder.setValue(name);
     RegionSpecifier regionSpecifier = regionSpecifierBuilder.build();
     getRequestBuilder.setRegion(regionSpecifier);
     Get.Builder getBuilder = Get.newBuilder();
-    getBuilder.setRow(ZeroCopyLiteralByteString.wrap("somerow".getBytes()));
+    getBuilder.setRow(HBaseZeroCopyByteString.wrap("somerow".getBytes()));
     getRequestBuilder.setGet(getBuilder.build());
     GetRequest getRequest = getRequestBuilder.build();
     RequestHeader header = headerBuilder.build();
@@ -86,8 +87,8 @@ public class TestPriorityRpc {
     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);
     Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);
     qosFunction.setRegionServer(mockRS);
-    assertTrue (qosFunction.apply(new Pair<RequestHeader, Message>(header, getRequest)) ==
-      HConstants.HIGH_QOS);
+    assertTrue(qosFunction.apply(new Pair<RequestHeader, Message>(header, getRequest)) ==
+        HConstants.HIGH_QOS);
   }
 
   @Test
@@ -100,8 +101,8 @@ public class TestPriorityRpc {
     headerBuilder.setMethodName("foo");
     RequestHeader header = headerBuilder.build();
     QosFunction qosFunc = regionServer.getQosFunction();
-    assertTrue (qosFunc.apply(new Pair<RequestHeader, Message>(header, null)) ==
-      HConstants.NORMAL_QOS);
+    assertTrue(qosFunc.apply(new Pair<RequestHeader, Message>(header, null)) ==
+        HConstants.NORMAL_QOS);
   }
 
   @Test
@@ -131,18 +132,18 @@ public class TestPriorityRpc {
     RegionScanner mockRegionScanner = Mockito.mock(RegionScanner.class);
     Mockito.when(mockRS.getScanner(12345)).thenReturn(mockRegionScanner);
     Mockito.when(mockRegionScanner.getRegionInfo()).thenReturn(mockRegionInfo);
-    Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);
+    Mockito.when(mockRS.getRegion((RegionSpecifier) Mockito.any())).thenReturn(mockRegion);
     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);
     Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);
 
     qosFunction.setRegionServer(mockRS);
 
-    assertTrue (qosFunction.apply(new Pair<RequestHeader, Message>(header, scanRequest)) ==
-      HConstants.HIGH_QOS);
+    assertTrue(qosFunction.apply(new Pair<RequestHeader, Message>(header, scanRequest)) ==
+        HConstants.HIGH_QOS);
 
     //the same as above but with non-meta region
     Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(false);
-    assertTrue (qosFunction.apply(new Pair<RequestHeader, Message>(header, scanRequest)) ==
-      HConstants.NORMAL_QOS);
+    assertTrue(qosFunction.apply(new Pair<RequestHeader, Message>(header, scanRequest)) ==
+        HConstants.NORMAL_QOS);
   }
 }
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSink.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSink.java
index ea5a693..2a08ef2 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSink.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/regionserver/TestReplicationSink.java
@@ -25,6 +25,7 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicBoolean;
 
+import com.google.protobuf.HBaseZeroCopyByteString;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
@@ -50,8 +51,6 @@ import org.junit.BeforeClass;
 import org.junit.Test;
 import org.junit.experimental.categories.Category;
 
-import com.google.protobuf.ZeroCopyLiteralByteString;
-
 @Category(MediumTests.class)
 public class TestReplicationSink {
   private static final Log LOG = LogFactory.getLog(TestReplicationSink.class);
@@ -262,9 +261,9 @@ public class TestReplicationSink {
     uuidBuilder.setLeastSigBits(HConstants.DEFAULT_CLUSTER_ID.getLeastSignificantBits());
     uuidBuilder.setMostSigBits(HConstants.DEFAULT_CLUSTER_ID.getMostSignificantBits());
     keyBuilder.setClusterId(uuidBuilder.build());
-    keyBuilder.setTableName(ZeroCopyLiteralByteString.wrap(table));
+    keyBuilder.setTableName(HBaseZeroCopyByteString.wrap(table));
     keyBuilder.setWriteTime(now);
-    keyBuilder.setEncodedRegionName(ZeroCopyLiteralByteString.wrap(HConstants.EMPTY_BYTE_ARRAY));
+    keyBuilder.setEncodedRegionName(HBaseZeroCopyByteString.wrap(HConstants.EMPTY_BYTE_ARRAY));
     keyBuilder.setLogSequenceNumber(-1);
     builder.setKey(keyBuilder.build());
     cells.add(kv);
-- 
1.7.0.4

